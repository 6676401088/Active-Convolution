name: "ACU_plain"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 10 dim: 3 dim: 32 dim: 32 } }
}

############################################################################################
#Base0
layer{
  name: "conv1_1"  type: "AConvFast"  bottom: "data"  top: "base0_3/0"
  param { lr_mult: 1    decay_mult: 1 }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 16    kernel_size: 1    stride: 1    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn1_1"  type: "BatchNorm"  bottom: "base0_3/0"  top: "base0_3/0"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale1_1"  type: "Scale"  bottom: "base0_3/0"  top: "base0_3/0"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu1_1"  type: "ReLU"  bottom: "base0_3/0"  top: "base0_3/0"}


############################################################################################
#Stage1
#---------------------------------------------------------------------
layer{
  name: "conv1_1/1"  type: "AConvFast"  bottom: "base0_3/0"  top: "conv1_1/1"
  param { lr_mult: 1    decay_mult: 1 }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 48    pad: 1    kernel_size: 3    stride: 1    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn1_1/1"  type: "BatchNorm"  bottom: "conv1_1/1"  top: "conv1_1/1"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale1_1/1"  type: "Scale"  bottom: "conv1_1/1"  top: "conv1_1/1"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu1_1/1"  type: "ReLU"  bottom: "conv1_1/1"  top: "conv1_1/1"}

layer{
  name: "conv1_1/2"  type: "AConvFast"  bottom: "conv1_1/1"  top: "conv1_1/2"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 48    pad: 1    kernel_size: 3    stride: 1    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn1_1/2"  type: "BatchNorm"  bottom: "conv1_1/2"  top: "conv1_1/2"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale1_1/2"  type: "Scale"  bottom: "conv1_1/2"  top: "conv1_1/2"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu1_1/2"  type: "ReLU"  bottom: "conv1_1/2"  top: "conv1_1/2"}

############################################################################################
#Stage2
#---------------------------------------------------------------------
#Residual 2_1
layer{
  name: "conv2_1/1"  type: "AConvFast"  bottom: "conv1_1/2"  top: "conv2_1/1"
  param { lr_mult: 1    decay_mult: 1 }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 96    pad: 1    kernel_size: 3    stride: 2    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn2_1/1"  type: "BatchNorm"  bottom: "conv2_1/1"  top: "conv2_1/1"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale2_1/1"  type: "Scale"  bottom: "conv2_1/1"  top: "conv2_1/1"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu2_1/1"  type: "ReLU"  bottom: "conv2_1/1"  top: "conv2_1/1"}

layer{
  name: "conv2_1/2"  type: "AConvFast"  bottom: "conv2_1/1"  top: "conv2_1/2"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 96    pad: 1    kernel_size: 3    stride: 1    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn2_1/2"  type: "BatchNorm"  bottom: "conv2_1/2"  top: "conv2_1/2"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale2_1/2"  type: "Scale"  bottom: "conv2_1/2"  top: "conv2_1/2"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu2_1/2"  type: "ReLU"  bottom: "conv2_1/2"  top: "conv2_1/2"}

############################################################################################
#Stage3
layer{
  name: "conv3_1/1"  type: "AConvFast"  bottom: "conv2_1/2"  top: "conv3_1/1"
  param { lr_mult: 1    decay_mult: 1 }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 192    pad: 1    kernel_size: 3    stride: 2    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn3_1/1"  type: "BatchNorm"  bottom: "conv3_1/1"  top: "conv3_1/1"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale3_1/1"  type: "Scale"  bottom: "conv3_1/1"  top: "conv3_1/1"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu3_1/1"  type: "ReLU"  bottom: "conv3_1/1"  top: "conv3_1/1"}

layer{
  name: "conv3_1/2"  type: "AConvFast"  bottom: "conv3_1/1"  top: "conv3_1/2"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  param {    lr_mult: 0.01    decay_mult: 0  }
  aconv_param{   normalize:true   pos_filler_std: -1    position_group: 1}
  convolution_param {    num_output: 192    pad: 1    kernel_size: 3    stride: 1    weight_filler { type: "msra" }    bias_term: false  }
}
layer{  name: "bn3_1/2"  type: "BatchNorm"  bottom: "conv3_1/2"  top: "conv3_1/2"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale3_1/2"  type: "Scale"  bottom: "conv3_1/2"  top: "conv3_1/2"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu3_1/2"  type: "ReLU"  bottom: "conv3_1/2"  top: "conv3_1/2"}

############################################################################################


layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv3_1/2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1000
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer{  name: "bn_fc1"  type: "BatchNorm"  bottom: "fc1"  top: "fc1"  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }}
layer{  name: "scale_fc1"  type: "Scale"  bottom: "fc1"  top: "fc1"  param { lr_mult: 1  decay_mult: 0 }  param { lr_mult: 1  decay_mult: 0 }  scale_param { bias_term: true }}
layer{  name: "relu_fc1"  type: "ReLU"  bottom: "fc1"  top: "fc1"}

layer {
  name: "prescore"
  type: "Pooling"
  bottom: "fc1"
  top: "prescore"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}

layer {
  name: "score"
  type: "Convolution"
  bottom: "prescore"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "prob"
  type: "Softmax"
  bottom: "score"
  top: "prob"
}
